# Mukul Chhabra

Applied AI engineer building production-grade LLM systems focused on Retrieval-Augmented Generation (RAG), evaluation frameworks, observability, and reliability.

I work at the intersection of research and real-world deployment â€” designing systems that are measurable, scalable, and production-ready.

---

## What I Work On

- Enterprise RAG architectures and hybrid retrieval
- LLM-as-a-judge evaluation frameworks
- Observability and telemetry for AI systems
- Failure mode analysis and reliability engineering
- Agent orchestration and tool-calling systems
- Cost, latency, and scalability tradeoffs

---

## Featured Projects

### Enterprise RAG Evaluation Framework
Case-aware evaluation pipeline for multi-turn RAG systems with strict JSON judge outputs and reproducible benchmarking.

https://github.com/mukulchhabra23/enterprise-rag-eval

### RAG Production Patterns
Production design patterns covering routing, hybrid retrieval, guardrails, caching, evaluation loops, and operational best practices.

https://github.com/mukulchhabra23/rag-production-patterns

### LLM Observability
Logging, tracing, and monitoring schemas for production LLM applications with evaluation telemetry patterns.

https://github.com/mukulchhabra23/llm-observability

---

## Research

Case-Aware LLM-as-a-Judge Evaluation for Enterprise Multi-Turn RAG  

https://arxiv.org/abs/2602.20379

---

## Systems Areas of Interest

- Evaluation methodology for generative systems
- Retrieval quality and ranking strategies
- Production AI architecture
- Reliability engineering for LLM applications
- Tool orchestration and agent workflows
- Cost modeling for large-scale inference

---

## Current Focus

Designing frameworks that help teams measure, debug, and improve real-world LLM systems at scale.

---

## Connect

LinkedIn: [https://www.linkedin.com  ](https://www.linkedin.com/in/mukulchhabra23/)

---
